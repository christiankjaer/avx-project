\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}

\title{Extending MLKit with vector instructions}
\author{Christian Kj√¶r Larsen}

\begin{document}

\maketitle

\section{Introduction}

In this section we will briefly describe the project, its purpose and the structure of this report.

\subsection{Project statement}

The goal of this project is to add packed vector support to the MLKit\cite{mlkit} Standard ML compiler using the AVX2 vector instructions present in modern Intel processors. The motivation is to be able to use this support to optimize programs written in Standard ML to exploit data parallism.

\subsection{Roadmap}

\begin{enumerate}
    \item We start by investingating other approaches to SIMD programming in higher level languages. This is in order to settle on a
        good abstraction that is fairly easy to program with.
    \item
        We then continue by designing a programming abstraction to be able to optimize a program in a generic way that is not tied to a particular instruction set or vector extensions.
        We also write some simple example programs that will work as motivating examples and show that the abstraction is actually useful.
    \item
        Finally we implement compiler support for Intel AVX in the MLKit Standard ML compiler by providing a set of intrinsics that compile to efficient code that use native vector instructions.
\end{enumerate}

\section{Background}

\subsection{Vector instructions in modern CPUs}

MMX, SSE and AVX in Intel processors.

Neon on ARM processors.

\subsection{Programming model and higher level languages}

\subsubsection{Intrinsics}

Intrinsic functions for C/C++ guaranteeing what code is generated when the functions are called.

\subsubsection{Rust}

Standard interface to generic functions that are lowered directly to LLVM and compiled for specific architectures there.
\url{https://github.com/rust-lang/stdsimd}

\subsubsection{.NET and Java}

\url{https://docs.microsoft.com/en-us/dotnet/api/system.numerics.vector?view=net-5.0}


\subsubsection{Challenges}

Do not tie the implementations to tightly to the specific instruction set. It should be fairly easy to change a program from say AVX2 to Neon.

\section{Design}

\section{Implementation}

\subsection{Modern hardware support}

\subsection{GCC}

Intrinsic functions.

Generic vector operations

\subsection{Higher level languages}

For C-sharp, System.Numeric.Vectors

For Java, jdk.incubator.vector


\section{Implementation}


\subsection{Generic interface}


A make function from a familar type, typically a tuple of elements.
A read function to read the familiar type again.


\subsubsection{Arithmetic}

Elementwise operations
Scalar operations

\subsubsection{Comparisons}

Mask type with all and any

\subsubsection{Masks}

Blend

\subsubsection{Handling arrays of odd length}






\subsubsection{Vectorizing a simple function}


\subsection{Implementation in the MLKit}

Boxed representation that is available to the programmer and an internal unboxed type that is available to the optimizer.

\subsection{Data types}

Reuse register allocation of vector registers since they completely overlap with xmm. Just rename to ymm when they are used in a vector instruction.

\subsubsection{Primops}

Both boxed and unboxed version of intrinsics. The unboxed ones are not available the the programmer, but are used internally in the optimizer.

\subsubsection{Unboxing}

Since Standard ML is polymorphic, there might be polymorphic functions that can receive arguments of any type. This is typically achieved by having a uniform representation of values. Typically a box (pointer to the underlying data). There is a substantial penalty for this, since in order to do operations on the underlying value, there is a level of indirection. For our new vector type we will have to use 16 bytes of memory in addition to the pointer to represent something that typically fits in a register.

Any operation that works on a boxed representation will typically have to unbox the data, do the operation and box the result again. This is very costly on modern hardware.

In some sense
\[
    box (unbox\ x) \equiv x
\]
and
\[
    unbox (box\ x) \equiv x
\]

\bibliographystyle{unsrt}
\bibliography{simd}

\end{document}
