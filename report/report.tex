\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{graphicx}

\lstset{language=ML}
\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}

\title{Extending MLKit with vector instructions}
\author{Christian Kj√¶r Larsen}


\begin{document}

\maketitle

\tableofcontents

\section{Introduction}

In this section we will briefly describe the project, its purpose and the structure of this report.

\subsection{Project statement}

The goal of this project is to add packed vector support to the MLKit\cite{mlkit} Standard ML compiler using the AVX2 vector instructions present in modern Intel processors. The motivation is to be able to use this support to optimize programs written in Standard ML to exploit data parallism.

\subsection{Roadmap}

\begin{enumerate}
    \item We start by investingating other approaches to SIMD programming in higher level languages. This is in order to settle on a
        good abstraction that is fairly easy to program with.
    \item
        We then continue by designing a programming abstraction to be able to optimize a program in a generic way that is not tied to a particular instruction set or vector extensions.
        We also write some simple example programs that will work as motivating examples and show that the abstraction is actually useful.
    \item
        Finally we implement compiler support for Intel AVX in the MLKit Standard ML compiler by providing a set of intrinsics that compile to efficient code that use native vector instructions.
\end{enumerate}

\section{Background}

\subsection{Vector instructions in modern CPUs}

Single instruction stream, but it works on multiple independent pieces of data.

Fewer data dependencies and fewer instructions to be decoded.

MMX, SSE and AVX in Intel processors.

Neon on ARM processors.

\subsection{Programming model and higher level languages}

\subsubsection{Intrinsics}

The primary way that people program with vector instructions is by using intrinsics.

Intrinsic functions for C/C++ guaranteeing what code is generated when the functions are called.

\subsubsection{Rust}

Standard interface to generic functions that are lowered directly to LLVM and compiled for specific architectures there.
\url{https://github.com/rust-lang/stdsimd}

Supposed to be portable, so you can write a function that works for vectors of, say, 4 64-bit floats, and then it would be lowered to the LLVM type \verb!<4 x double>!. The problem of choosing good instruction for certain operations are then delegated to the LLVM backend.

\subsubsection{.NET and Java}

\url{https://docs.microsoft.com/en-us/dotnet/api/system.numerics.vector?view=net-5.0}


\subsubsection{Challenges}

One major challenge is not to tie the implementations to tightly to the specific instruction set. It should be fairly easy to change a program from say AVX2 to Neon. This then gives the problem of instruction selection. Do you expose direct versions of the AVX2 instructions, and then make other instruction sets emulate those, or do you try to find a common ground, that makes useful operations with good performance available on all CPUs.

Take for instance a horizontal add,
\[
    \mathtt{hadd}\ [a_1, \ldots, a_4] = a_1 + \cdots + a_4
\]
for reducing a 4 element vector. The AVX2 instruction set has no direct support, and the most efficient implementation might depend on vector sizes and element types. The proposed RISC-V vector extensions directly expose a \texttt{vfredsum.vs} that directly reduces a vector.

Since we in this project only focus on MLKits 64 bit intel backend, we restrict ourselves to vectors of reals (64 bit floats) of 4 elements. This is supported by AVX2 which is widely supported now. We will of course keep in mind to design our library such that it is not too tied to AVX2.

\section{Design of a vector signature}

Aritmetic instructions, conditionals, reductions, loads and stores.
Boolean operations

Arithmetic: plus, minus, multiply, divide, min, max
Boolean ops on masks: and, or, not, etc.

Reductions for masks: all, any
Reductions for vectors: sum, product, min, max

construct and destruct vectors into SML values
Loads and stores into unboxed arrays


\subsection{Generic interface}

SML is pretty simple, parameterizing modules too much makes the library hard to use.

\texttt{INT4} for 4 integers (we will not work with this for now)

\texttt{REAL4} for 4 reals.

\begin{lstlisting}[frame=single]
signature REAL4 = sig

  type element = real
  type interface = real * real * real * real

  type simd
  type mask

  val mk : interface -> simd
  val read : simd -> interface

  (* arithmetic operations (vectors and scalars) *)
  val add : simd * simd -> simd
  val adds : simd * element -> simd
  (* and so on *)

  (* comparisons (vectors and scalars) *)
  val lt : simd * simd -> mask
  val lts : simd * element -> mask
  (* and so on *)

  (* operations on masks *)
  val and_ : mask * mask -> mask
  val or_ : mask * mask -> mask
  val not_ : mask -> mask

  (* reductions *)
  val all : mask -> boolean
  val any : mask -> boolean
  val sum : simd -> element
  val product : simd -> element

  (* conditional operations *)
  val blend : simd * simd * mask -> simd
end
\end{lstlisting}

\subsubsection{Arithmetic}

Elementwise operations
Scalar operations

\subsubsection{Comparisons}

Mask type with all and any

\subsubsection{Masks}

Blend that 

\subsection{Pure SML structure}

It is pretty easy to implement a pure SML structure that we can use to test our hardware accelerated version against. We just use tuples of reals for vectors and tuples of booleans for masks.
\begin{lstlisting}[frame=single]
structure Tup4 : REAL4 = struct
  type simd = real * real * real * real
  type mask = bool * bool * bool * bool

  fun mk a = a
  fun read a = a

  fun all (m1, m2, m3, m4) = m1 andalso m2 andalso m3 andalso m4

  (* And so on *)
end
\end{lstlisting}

\subsection{Writing programs}

Numeric programs.

Branches (always compute both, and then select based on mask)

Reductions to booleans and scalars.

\subsubsection{Vectorizing mandelbrot}

In the classic mandelbrot algorithm, a single pixel is calculated by applying a function to a coordinate until divergence.

\begin{lstlisting}
fun mandelbrot (x0: real, y0: real): int =
  let
    fun go iter x y =
      if (x*x + y*y <= 4.0 andalso iter < 1000)
      then go (iter + 1) (x*x - y*y + x0) (2.0*x*y + y0)
      else iter
  in
    go 0 0.0 0.0
  end
\end{lstlisting}

The way to approach it is to consider 4 pixels $(x_1, y), \ldots, (x_4, y)$. The problem is that for 4 pixels it might be the case that some diverge and some converge. We can use masks to essentially block the updates for pixels that have converged already.

We keep a mask $(\texttt{true}, \texttt{true}, \texttt{true}, \texttt{true})$ to signal whether a single pixel converged. We keep updating the iteration count while the corresponding element in the mask is \texttt{true}. We keep iterating as long as any make element is true or at some limit like the original algorithm.

\begin{lstlisting}
functor Mandelbrot(Vec: REAL4) = struct
  val zero = Vec.broadcast 0.0

  fun mandelbrot (x0: Vec.simd, y0: real): Vec.simd =
    let
      fun go iter mask x =
        if (Vec.any mask andalso iter < 1000) then
          let
            val x2 = Vec.mul(x, x)
            val y2 = Vec.mul(y, y)
            val computeX = Vec.add (Vec.sub (x2, y2), x0)
            val computeY = Vec.adds (Vec.muls (Vec.mul (x, y), 2.0), y0)

            val newMask = Vec.lts (Vec.add(x2, y2), 4.0)

            val updated = Vec.blend (iters, Vec.adds (iters, 1.0), mask)
            val newX = Vec.blend (x, computeX, mask)
            val newY = Vec.blend (x, computeY, mask)
          in
            go (iter + 1) newMask updated newX newY
          end
        else iters
    in
      go 0 Vec.true zero zero zero
    end
end
\end{lstlisting}

We use the \verb!blend! function to conditionally update element only when the if-condition in the original program would have been true. It is not super high level, so it feels a bit like manually programming with low level vectors, but that is the point. We can use the module to optimize library functions for efficiency.

\section{AVX2 implementation in the MLKit}

\subsection{Primop definition}

We steal the intel terminology that m256d is a 256 bit vector of double precision floating point.

\subsection{Internal representation}

2. add unboxed internal representation and make operations for boxing and unboxing. Change the backend to use vector registers for some operations.

f256 for the unboxed type.

\subsection{Implementing boxed operations}

3. make the optimizer rewrite boxed operations $f_{\mathrm{boxed}}\ x$ to unboxed
\[
    \mathtt{box}\ (f_{\mathrm{unboxed}} (\mathtt{unbox}\ x))
\]

Then we only have to implement support for unboxed operations

\subsection{Instruction selection}

4. Select instructions to implement the unboxed primops.

Some are straight forward, some require a sequence of operations. Simple arithmetic vs. reductions.

On figure XXX we have sketched out our implementation of a horizontal sum of a vector register.

Assume that the argument is in register \verb!ymm0!, then the following instruction sequence will place the sum of all elements in the bottom of register \verb!xmm1!:

\begin{verbatim}
vextractf128 0x1, %ymm0, %xmm1
vaddpd %xmm0, %xmm1, %xmm0
vunpckhpd %xmm1, %xmm1, %xmm0
vaddsd %xmm1, %xmm0, %xmm1
\end{verbatim}

\includegraphics[width=\textwidth]{sum.png}


Since we did not want to modify the memory allocation in MLKit too much, we have made the decision to rely on the unaligned memory operations that are possible in AVX2. They might be a little slower than making sure that all accesses are properly aligned.

\subsection{Unboxing}
5. Optimize the intermediate code to get rid of unnessecary boxing operations.

\subsection{Signature using primops}

6. Implement the REAL4 signature using the primops.

Pretty straight forward. We have primops for all the things.
\begin{lstlisting}[frame=single]
structure M256d :> REAL4 = struct
  type m256d = string
  type simd = m256d
  type mask = m256d
  type interface = real * real * real * real

  fun mk (v: interface): m256d = prim("__blockf64", v)

  fun broadcast (v: real): m256d = prim("__m256d_broadcast", v)
  fun add (a: m256d, b: m256d): m256d = prim("__m256d_plus", (a,b))
  fun adds (a: m256d, b: real): m256d = add(a, broadcast b)

  (* And so on *)
 end
\end{lstlisting}

\subsection{Data types}

The MLKit has a boxed floating point representation accessible to the programmer as the \verb!real! type in Standard ML. Internally in the optimizer, unnessecary boxing operations are avoided by using unboxed operations directly on floating point registers thereby avoiding expensive memory operations in basic blocks. Due to the uniform memory represenation, these unboxed floats can not be passed to generic functions and should therefore not be exposed to the programmer.

We will do something similar for our vector representation. A boxed representation will be visible to the programmer, but internally a \verb!F256! type will be used to represent a register containing 4 64-bit floating point numbers.

\subsection{Primops}

Except for memory operations, the primops will correspond directly to the AVX2 instructions. For now borrowing from intel terminology, \verb!__m256d! will be the prefix for operations on sets of 4 reals.

\subsubsection{Loading and storing}

Reuse f64 blocks for both reading and writing to arrays and for boxing.

\verb!blockf64_sub_m256d!

\verb!blockf64_update_m256d!

Can be used to implement a fast fold, map, etc. for unboxed arrays of reals.


TODO: Make sure that memory accesses are aligned.

\subsubsection{Arithmetic operations}

\verb!__m256d_broadcast! will broadcast one \verb!real! into all 4 elements of a 4 element vector.

\verb!__m256d_plus! will do vector addition. We will have similar primops for other arithmetic operations.

\subsubsection{Conditional operations and masks}

The conditional operations all have the type \verb!m256d -> m256d -> mask! where the mask is also a vector residing in a vector register.

\verb!__m256d_blend! has the type \verb!m256d -> m256d -> mask -> m256d! where we can blend two vectors based on a mask.

\verb!__m256d_all!, \verb!__m256d_any! have the type \verb!mask -> bool!

The instruction \verb!vmovmsk! will move the 4 bit masks into an integer register and we can then implement the conditional operations.

For \verb!all! we move \verb!true! into the destination if the mask is $1111$ otherwise we set it to \verb!false!.
For \verb!any! we move \verb!true! into the destination if the mask is not $0000$ otherwise we set it to \verb!false!.

\subsubsection{Primops}

Both boxed and unboxed version of intrinsics. The unboxed ones are not available the the programmer, but are used internally in the optimizer.

\subsubsection{Boxing}

An representation of a boxing operation \verb!__f256_box! will be rewritten in a final step of the optimizer to be
\begin{lstlisting}
let
  val box = alloc_vector ()
  val ()  = store_vector (value, box)
in box
\end{lstlisting}
Where the two operations will be distinct primops. This makes it easier to manipulate boxing operations internally in the optimizer.


We reuse the blockf64 primop for allocating boxes. This means that the stored 

Since Standard ML is polymorphic, there might be polymorphic functions that can receive arguments of any type. This is typically achieved by having a uniform representation of values. Typically a box (pointer to the underlying data). There is a substantial penalty for this, since in order to do operations on the underlying value, there is a level of indirection. For our new vector type we will have to use 16 bytes of memory in addition to the pointer to represent something that typically fits in a register.

Any operation that works on a boxed representation will typically have to unbox the data, do the operation and box the result again. This is very costly on modern hardware.

In some sense
\[
    box (unbox\ x) \equiv x
\]
and
\[
    unbox (box\ x) \equiv x
\]

\section{Data-parallel programming}

Using the unboxed real array from MLKit, we implement vectorized traversals.

\section{Evaluation}

\subsection{Inspecting assembly code from example programs}

We make som functions that calls the primops with the right types.
\begin{lstlisting}
type m256d = string
fun broadcast (a: real): m256d = prim("__m256d_broadcast", a)
fun add (a: m256d, b: m256d): m256d = prim("__m256d_plus", (a, b))
fun adds (a: m256d, b: real): m256d = add(a, broadcast(b))

fun mul (a: m256d, b: m256d): m256d = prim("__m256d_mul", (a, b))
fun muls (a: m256d, b: real): m256d = mul(a, broadcast(b))

fun sub (a: m256d, b: m256d): m256d = prim("__m256d_minus", (a, b))
fun subs (a: m256d, b: real): m256d = sub(a, broadcast(b))
\end{lstlisting}
A simple example program only consisting of arithmetic operations.
\begin{lstlisting}
fun g (x: m256d) = add (x, mk (0.0, 1.0, 2.0, 3.0))
fun f () =
let
  val a: m256d = mk (10.0, 20.0, 30.0, 40.0)
  val b: m256d = mul (a, a)
  val c: m256d = adds (b, 3.0)
  val d: m256d = sub (c, a)
  val e: m256d = g d
in 
  e
end
\end{lstlisting}
The core of the generated assembly code is the following
Disregarding the loading of vector literals, the resulting code is fully unboxed and just has a series of vector instructions.

For branching we want to print 1.0 if any of the elements of \verb!x! are greater than their corresponding element in \verb!y! and 0.0 otherwise.

\begin{lstlisting}
fun gt (a: simd, b: simd): mask = prim("__m256d_greater", (a,b))
fun any (a: mask): bool = prim("__m256d_any", a)
let
  val x = mk (2.0, 3.0, 4.0, 5.0)
  val y = mk (3.0, 3.0, 3.0, 3.0)
  val b = any (gt (x, y))
in 
  if b then printReal 1.0 else printReal 0.0
end
\end{lstlisting}

This generates the following code

\begin{verbatim}
  # Code to load x into ymm8 y into ymm12 above
  vcmppd $0xE,%ymm8,%ymm12,%ymm8
  vmovmskpd %ymm8,%rax
  cmpq $0x0,%rax
  movq $1,%rax
  movq $3,%r10
  cmovne %r10,%rax
  cmpq $3,%rax
  jne .LLab.newSelLab436branch.auto.mlbbranch.sml1
  movq $DLab.FloatLab32437branch.auto.mlbbranch.sml1,%rdi
  call printReal
  jmp .LLab.exitSwitchLab434branch.auto.mlbbranch.sml1
  .p2align 0x4
.LLab.newSelLab436branch.auto.mlbbranch.sml1:
  movq $DLab.FloatLab31435branch.auto.mlbbranch.sml1,%rdi
  call printReal
  .p2align 0x4
.LLab.exitSwitchLab434branch.auto.mlbbranch.sml1:
\end{verbatim}

Again fully unboxed.

\subsection{Benchmarks}

In this section we will benchmark small example programs and try to explain why they are fast, or why in some cases they are slower than expected.

\url{https://www.agner.org/optimize/blog/read.php?i=838}

Using \texttt{RealTable}\footnote{\url{https://github.com/melsman/mlkit/blob/master/basis/RealTable.sml}}

\subsubsection{Arithmetic}

For the first case we will consider modifying an array $[x_1, \ldots, x_n]$ to $[x_1(x_1 + 2), \ldots, x_n(x_n + 2)]$. The code to beat is:
\begin{lstlisting}
RealTable.modify (fun x => x * (x + 2.0)) t
\end{lstlisting}

We consider two versions. One that will make a scalar addition, which will do a broadcast with $2.0$ for each iteration:
\begin{lstlisting}
RealTable.modify_simd (fun x => mul (x, adds (x, 2.0))) t
\end{lstlisting}
The second one will store a vector $\{ 2.0, 2.0, 2.0, 2.0 \}$, and do vector addition for each iteration. This will require a memory operation instead of a broadcast.
\begin{lstlisting}
let
  val two = broadcast 2.0
in
  RealTable.modify_simd (fun x => mul (x, add (x, two))) t
end
\end{lstlisting}
The result for various array sizes are for AMD Ryzen:
\begin{center}
\begin{tabular}{ c c c c }
    Elements & Scalar (ms) & Vector 1 & Vector 2 (ms) \\
    $10^4$ & $0.015$ & $0.312$ & $0.006$ \\
    $10^5$ & $0.182$ & $2.787$ & $0.042$ \\
    $10^6$ & $1.013$ & $18.494$ & $0.489$ \\
    $10^7$ & $17.518$ & $216.674$ & $7.184$ \\
    $10^8$ & $182.967$ & $2175.133$ & $74.729$ \\
\end{tabular}
\end{center}

The result for various array sizes are for Intel i5:
\begin{center}
\begin{tabular}{ c c c c }
    Elements & Scalar (ms) & Vector 1 & Vector 2 (ms) \\
    $10^4$ & $0.121$ & $0.043$ & $0.028$ \\
    $10^5$ & $1.262$ & $0.758$ & $0.290$ \\
    $10^6$ & $6.000$ & $4.361$ & $1.027$ \\
    $10^7$ & $33.639$ & $21.238$ & $12.373$ \\
    $10^8$ & $354.351$ & $166.834$ & $119.857$ \\
\end{tabular}
\end{center}

It turns out that 

\subsubsection{Mandelbrot}

\subsubsection{Conditionals}

\begin{lstlisting}
RealTable.modify (fun x => if x > 4096.0 then x else x * x) t
\end{lstlisting}

\begin{lstlisting}
let val y = broadcast 4096.0
in RealTable.modify_simd
    (fun x => Simd4.blend (Simd4.mul (x, x), x, Simd4.gt (x, y)))
    t
\end{lstlisting}

\begin{center}
\begin{tabular}{ c c c }
    Elements & Scalar (ms) & Vector (ms) \\
    $10^4$ & $0.125$ & $0.005$ \\
    $10^5$ & $1.332$ & $0.051$ \\
    $10^6$ & $7.203$ & $0.453$ \\
    $10^7$ & $70.075$ & $7.250$
\end{tabular}
\end{center}

But this bechmark is a little misleading, since it uses a conditional move instruction instead of jumps, and therefore is highly efficient on modern hardware. The speed is of the vectorized version is comparable to the aritmetic program from before.

\section{Future work}

Aligned memory accesses

Unboxed tail recursive functions for tight loops. Take for instance a sum function

\begin{lstlisting}
foldl Simd4.add (Simd4.broadcast) arr
\end{lstlisting}

foldl will probably be tailrecursively with a vector accumulator. This is the common way to do it. The problem is that we have to box and unbox for every 4 elements. The current boxing implementation is very expensive.

Common subexpression elimination to reduce unboxing load.

Consider the function \texttt{foo}
\begin{lstlisting}
fun foo (x: m256d) =
  let
    val y = add (x, broadcast 2.0)
    val z = foo x
  in mul (z, x) end
\end{lstlisting}

\texttt{foo} will have an unbox for each occurence of \texttt{x} in arithmetic operations. It would be better to make \texttt{val x' = unbox x} available in the scope, and then replace occurences of \texttt{unbox x} with \texttt{x'} when the boxed versions are expanded. This will require a bit more complicated analysis of the program. It might be combined with common subexpression elimination.

The optimizer cannot really recognize the boxed vectors, since they just are represented using a string type. Therefore there are cases where spurious unboxes are put in the program. It is also possible to use string operations directly on a boxed vector, which is not disirable.

If the last operation is a box, then the instruction should write directly to memory instead of doing a move. Peephole optimization.

\section{Conclusion}

AMD is fucked.


\bibliographystyle{unsrt}
\bibliography{simd}

\end{document}
