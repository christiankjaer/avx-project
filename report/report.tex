\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{listings}

\lstset{language=ML}
\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}

\title{Extending MLKit with vector instructions}
\author{Christian KjÃ¦r Larsen}



\begin{document}

\maketitle

\section{Introduction}

In this section we will briefly describe the project, its purpose and the structure of this report.

\subsection{Project statement}

The goal of this project is to add packed vector support to the MLKit\cite{mlkit} Standard ML compiler using the AVX2 vector instructions present in modern Intel processors. The motivation is to be able to use this support to optimize programs written in Standard ML to exploit data parallism.

\subsection{Roadmap}

\begin{enumerate}
    \item We start by investingating other approaches to SIMD programming in higher level languages. This is in order to settle on a
        good abstraction that is fairly easy to program with.
    \item
        We then continue by designing a programming abstraction to be able to optimize a program in a generic way that is not tied to a particular instruction set or vector extensions.
        We also write some simple example programs that will work as motivating examples and show that the abstraction is actually useful.
    \item
        Finally we implement compiler support for Intel AVX in the MLKit Standard ML compiler by providing a set of intrinsics that compile to efficient code that use native vector instructions.
\end{enumerate}

\section{Background}

\subsection{Vector instructions in modern CPUs}

MMX, SSE and AVX in Intel processors.

Neon on ARM processors.

\subsection{Programming model and higher level languages}

\subsubsection{Intrinsics}

Intrinsic functions for C/C++ guaranteeing what code is generated when the functions are called.

\subsubsection{Rust}

Standard interface to generic functions that are lowered directly to LLVM and compiled for specific architectures there.
\url{https://github.com/rust-lang/stdsimd}

\subsubsection{.NET and Java}

\url{https://docs.microsoft.com/en-us/dotnet/api/system.numerics.vector?view=net-5.0}


\subsubsection{Challenges}

Do not tie the implementations to tightly to the specific instruction set. It should be fairly easy to change a program from say AVX2 to Neon.

\section{Design}

MLKit has a 64 bit intel backend, and and we restrict ourselves to vectors of reals (64 bit floats) of 4 elements. This is supported by AVX2 which is widely supported now.

\section{Implementation}


\subsection{Generic interface}

\begin{lstlisting}[frame=single]
signature SIMD4 = sig
  type element = real
  type interface = real * real * real * real

  type simd
  type mask

  val mk : interface -> simd
  val read : simd -> interface

  (* arithmetic operations (vectors and scalars) *)
  val add : simd * simd -> simd
  val adds : simd * element -> simd
  (* and so on *)

  (* comparisons (vectors and scalars) *)
  val lt : simd * simd -> mask
  val lts : simd * element -> mask
  (* and so on *)

  (* predicates *)
  val all : mask -> boolean
  val any : mask -> boolean

  (* conditional operations *)
  val blend : simd * simd * mask -> simd
end
\end{lstlisting}


\subsubsection{Arithmetic}

Elementwise operations
Scalar operations

\subsubsection{Comparisons}

Mask type with all and any

\subsubsection{Masks}

Blend that 

\subsubsection{Handling arrays of odd length}


Basically a fast map on arrays with a mask at the end.
Tabulate would be nice.

Have like a RealTable but with SIMD operations. Odd lengths would be handled by blend.

\subsubsection{Vectorizing mandelbrot}

In the classic mandelbrot algorithm, a single pixel is calculated by applying a function to a coordinate until divergence.

\begin{lstlisting}
fun mandelbrot (x0: real, y0: real): int =
  let
    fun go iter x y =
      if (x*x + y*y <= 4.0 andalso iter < 1000)
      then go (iter + 1) (x*x - y*y + x0) (2.0*x*y + y0)
      else iter
  in
    go 0 0.0 0.0
  end
\end{lstlisting}

The way to approach it is to consider 4 pixels $(x_1, y), \ldots, (x_4, y)$. The problem is that for 4 pixels it might be the case that some diverge and some converge. We can use masks to essentially block the updates for pixels that have converged already.

We keep a mask $(\texttt{true}, \texttt{true}, \texttt{true}, \texttt{true})$ to signal whether a single pixel converged. We keep updating the iteration count while the corresponding element in the mask is \texttt{true}. We keep iterating as long as any make element is true or at some limit like the original algorithm.

We can 

\begin{lstlisting}
functor Mandelbrot(Vec: SIMD4) = struct
  val zero = Vec.mk (0.0, 0.0, 0.0, 0.0)
  val one = Vec.mk (1.0, 1.0, 1.0, 1.0)

  fun mandelbrot (x0: Vec.simd, y0: real): Vec.simd =
    let
      fun go iter mask x =
        if (Vec.any mask andalso iter < 1000) then
          let
            val x2 = Vec.mul(x, x)
            val y2 = Vec.mul(y, y)
            val computeX = Vec.add (Vec.sub (x2, y2), x0)
            val computeY = Vec.adds (Vec.muls (Vec.mul (x, y), 2.0), y0)

            val newMask = Vec.lts (Vec.add(x2, y2), 4.0)

            val updated = Vec.blend (iters, Vec.add (iters, one), mask)
            val newX = Vec.blend (x, computeX, mask)
            val newY = Vec.blend (x, computeY, mask)
          in
            go (iter + 1) newMask updated newX newY
          end
        else iters
    in
      go 0 Vec.true zero zero zero
    end
end
\end{lstlisting}

We use the \verb!blend! function to conditionally update element only when the if-condition in the original program would have been true. It is not super high level, so it feels a bit like manually programming with low level vectors, but that is the point. We can use the module to optimize library functions for efficiency.

\subsection{Implementation in the MLKit}

Boxed representation that is available to the programmer and an internal unboxed type that is available to the optimizer.

\subsection{Data types}

The MLKit has a boxed floating point representation accessible to the programmer as the \verb!real! type in Standard ML. Internally in the optimizer, unnessecary boxing operations are avoided by using unboxed operations directly on floating point registers thereby avoiding expensive memory operations in basic blocks. Due to the uniform memory represenation, these unboxed floats can not be passed to generic functions and should therefore not be exposed to the programmer.

We will do something similar for our vector representation. A boxed representation will be visible to the programmer, but internally a \verb!F256! type will be used to represent a register containing 4 64-bit floating point numbers.

\subsection{Primops}

Except for memory operations, the primops will correspond directly to the AVX2 instructions. For now borrowing from intel terminology, \verb!__m256d! will be the prefix for operations on sets of 4 reals.

\subsubsection{Loading and storing}

Reuse f64 blocks for both reading and writing to arrays and for boxing.

\verb!blockf64_sub_m256d!

\verb!blockf64_update_m256d!

Can be used to implement a fast fold, map, etc. for unboxed arrays of reals.


TODO: Make sure that memory accesses are aligned.

\subsubsection{Arithmetic operations}

\verb!__m256d_broadcast! will broadcast one \verb!real! into all 4 elements of a 4 element vector.

\verb!__m256d_plus! will do vector addition. We will have similar primops for other arithmetic operations.

\subsubsection{Conditional operations and masks}

The conditional operations all have the type \verb!m256d -> m256d -> mask! where the mask is also a vector residing in a vector register.

\verb!__m256d_blend! has the type \verb!m256d -> m256d -> mask -> m256d! where we can blend two vectors based on a mask.

\verb!__m256d_all!, \verb!__m256d_any! have the type \verb!mask -> bool!

The instruction \verb!vmovmsk! will move the 4 bit masks into an integer register and we can then implement the conditional operations.

For \verb!all! we move \verb!true! into the destination if the mask is $1111$ otherwise we set it to \verb!false!.
For \verb!any! we move \verb!true! into the destination if the mask is not $0000$ otherwise we set it to \verb!false!.

\subsubsection{Primops}

Both boxed and unboxed version of intrinsics. The unboxed ones are not available the the programmer, but are used internally in the optimizer.

\subsubsection{Boxing}

An representation of a boxing operation \verb!__f256_box! will be rewritten in a final step of the optimizer to be
\begin{lstlisting}
let
  val box = alloc_vector ()
  val ()  = store_vector (value, box)
in box
\end{lstlisting}
Where the two operations will be distinct primops. This makes it easier to manipulate boxing operations internally in the optimizer.


We reuse the blockf64 primop for allocating boxes. This means that the stored 

Since Standard ML is polymorphic, there might be polymorphic functions that can receive arguments of any type. This is typically achieved by having a uniform representation of values. Typically a box (pointer to the underlying data). There is a substantial penalty for this, since in order to do operations on the underlying value, there is a level of indirection. For our new vector type we will have to use 16 bytes of memory in addition to the pointer to represent something that typically fits in a register.

Any operation that works on a boxed representation will typically have to unbox the data, do the operation and box the result again. This is very costly on modern hardware.

In some sense
\[
    box (unbox\ x) \equiv x
\]
and
\[
    unbox (box\ x) \equiv x
\]

\subsection{Data-parallel programming}

Using the unboxed real array from MLKit, we implement vectorized traversals.

\section{Evaluation}

\subsection{Inspecting assembly code from example programs}

We make som functions that calls the primops with the right types.
\begin{lstlisting}
type m256d = string
fun broadcast (a: real): m256d = prim("__m256d_broadcast", a)
fun add (a: m256d, b: m256d): m256d = prim("__m256d_plus", (a, b))
fun adds (a: m256d, b: real): m256d = add(a, broadcast(b))

fun mul (a: m256d, b: m256d): m256d = prim("__m256d_mul", (a, b))
fun muls (a: m256d, b: real): m256d = mul(a, broadcast(b))

fun sub (a: m256d, b: m256d): m256d = prim("__m256d_minus", (a, b))
fun subs (a: m256d, b: real): m256d = sub(a, broadcast(b))
\end{lstlisting}
A simple example program only consisting of arithmetic operations.
\begin{lstlisting}
fun g (x: m256d) = add (x, mk (0.0, 1.0, 2.0, 3.0))
fun f () =
let
  val a: m256d = mk (10.0, 20.0, 30.0, 40.0)
  val b: m256d = mul (a, a)
  val c: m256d = adds (b, 3.0)
  val d: m256d = sub (c, a)
  val e: m256d = g d
in 
  e
end
\end{lstlisting}
The core of the generated assembly code is the following
\begin{verbatim}
vmulpd %ymm10,%ymm10,%ymm12
movq $DLab.FloatLab51747simd.auto.mlbsimd.sml1,%r10
movsd (%r10),%xmm8
vbroadcastsd %xmm8,%ymm8
vaddpd %ymm8,%ymm12,%ymm8
vsubpd %ymm10,%ymm8,%ymm4
xorps %xmm8,%xmm8
movq $DLab.FloatLab50746simd.auto.mlbsimd.sml1,%r10
movsd (%r10),%xmm10
movq $DLab.FloatLab49745simd.auto.mlbsimd.sml1,%r10
movsd (%r10),%xmm12
movq $DLab.FloatLab48744simd.auto.mlbsimd.sml1,%r10
movsd (%r10),%xmm2
leaq 16(%rsp),%rsi
movsd %xmm8,8(%rsi)
movsd %xmm10,16(%rsi)
movsd %xmm12,24(%rsi)
movsd %xmm2,32(%rsi)
vmovupd 8(%rsi),%ymm8
vaddpd %ymm8,%ymm4,%ymm8
\end{verbatim}
Disregarding the loading of vector literals, the resulting code is fully unboxed and just has a series of vector instructions.

For branching we want to print 1.0 if any of the elements of \verb!x! are greater than their corresponding element in \verb!y! and 0.0 otherwise.

\begin{lstlisting}
fun gt (a: simd, b: simd): mask = prim("__m256d_greater", (a,b))
fun any (a: mask): bool = prim("__m256d_any", a)
let
  val x = mk (2.0, 3.0, 4.0, 5.0)
  val y = mk (3.0, 3.0, 3.0, 3.0)
  val b = any (gt (x, y))
in 
  if b then printReal 1.0 else printReal 0.0
end
\end{lstlisting}

This generates the following code

\begin{verbatim}
  # Code to load x into ymm8 y into ymm12 above
  vcmppd $0xE,%ymm8,%ymm12,%ymm8
  vmovmskpd %ymm8,%rax
  cmpq $0x0,%rax
  movq $1,%rax
  movq $3,%r10
  cmovne %r10,%rax
  cmpq $3,%rax
  jne .LLab.newSelLab436branch.auto.mlbbranch.sml1
  movq $DLab.FloatLab32437branch.auto.mlbbranch.sml1,%rdi
  call printReal
  jmp .LLab.exitSwitchLab434branch.auto.mlbbranch.sml1
  .p2align 0x4
.LLab.newSelLab436branch.auto.mlbbranch.sml1:
  movq $DLab.FloatLab31435branch.auto.mlbbranch.sml1,%rdi
  call printReal
  .p2align 0x4
.LLab.exitSwitchLab434branch.auto.mlbbranch.sml1:
\end{verbatim}

Again fully unboxed.

\subsection{Benchmarks}

Using \texttt{RealTable}\footnote{\url{https://github.com/melsman/mlkit/blob/master/basis/RealTable.sml}}

\subsubsection{Arithmetic}

\begin{lstlisting}
RealTable.modify (fun x => x * (x + x)) t
\end{lstlisting}

\begin{lstlisting}
RealTable.modify_simd (fun x => Simd4.mul (x, Simd4.add (x, x))) t
\end{lstlisting}

\begin{center}
\begin{tabular}{ c c c }
    Elements & Scalar (ms) & Vector (ms) \\
    $10^4$ & $0.015$ & $0.004$ \\
    $10^5$ & $0.155$ & $0.039$ \\
    $10^6$ & $0.861$ & $0.425$ \\
    $10^7$ & $18.413$ & $7.240$
\end{tabular}
\end{center}

\subsubsection{Mandelbrot}

\subsubsection{Conditionals}

\begin{lstlisting}
RealTable.modify (fun x => if x > 4096.0 then x else x * x) t
\end{lstlisting}

\begin{lstlisting}
let val y = broadcast 4096.0
in RealTable.modify_simd
    (fun x => Simd4.blend (Simd4.mul (x, x), x, Simd4.gt (x, y)))
    t
\end{lstlisting}

\begin{center}
\begin{tabular}{ c c c }
    Elements & Scalar (ms) & Vector (ms) \\
    $10^4$ & $0.125$ & $0.005$ \\
    $10^5$ & $1.332$ & $0.051$ \\
    $10^6$ & $7.203$ & $0.453$ \\
    $10^7$ & $70.075$ & $7.250$
\end{tabular}
\end{center}

But this bechmark is a little misleading, since it uses a conditional move instruction instead of jumps, and therefore is highly efficient on modern hardware. The speed is of the vectorized version is comparable to the aritmetic program from before.

\section{Future work}

Aligned memory accesses

Unboxed tail recursive functions for tight loops. Take for instance a sum function

\begin{lstlisting}
foldl Simd4.add (Simd4.broadcast) arr
\end{lstlisting}

foldl will probably be tailrecursively with a vector accumulator. This is the common way to do it. The problem is that we have to box and unbox for every 4 elements. The current boxing implementation is very expensive.

\section{Conclusion}


\bibliographystyle{unsrt}
\bibliography{simd}

\end{document}
